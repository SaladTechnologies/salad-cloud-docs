{
  "type": "object",
  "properties": {
    "model": {
      "type": "string",
      "enum": ["stabilityai/stable-diffusion-xl-base-1.0"]
    },
    "params": {
      "type": "object",
      "properties": {
        "instance_prompt": {
          "type": "string",
          "description": "The prompt with identifier specifying the instance, e.g. 'photo of a TOK dog', 'in the style of TOK'"
        },
        "instance_images": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "minItems": 1,
          "maxItems": 100,
          "description": "List of accessible image URLs to be used as instance images."
        },
        "class_preset": {
          "type": "string",
          "enum": [
            "photo_of_a_man",
            "photo_of_a_woman",
            "photo_of_a_nonbinary_person",
            "photo_of_a_transfeminine_person",
            "photo_of_a_trans_man",
            "photo_of_a_trans_woman",
            "photo_of_a_dog",
            "photo_of_a_cat",
            "photo_of_a_bird",
            "photo_of_a_fish",
            "photo_of_a_snake",
            "photo_of_a_horse",
            "photo_of_a_guinea_pig",
            "photo_of_a_hamster",
            "photo_of_a_rabbit",
            "photo_of_a_house",
            "photo_of_a_car",
            "photo_of_a_motorcycle",
            "photo_of_a_truck",
            "photo_of_a_book",
            "photo_of_a_bracelet",
            "photo_of_a_camera",
            "photo_of_a_guitar",
            "photo_of_a_handbag",
            "photo_of_a_hat",
            "photo_of_a_necklace",
            "photo_of_a_pen",
            "photo_of_a_shirt",
            "photo_of_a_television",
            "photo_of_a_wallet",
            "photo_of_a_watch",
            "photo_of_a_water_bottle",
            "photo_of_drums",
            "photo_of_earrings",
            "photo_of_pants",
            "photo_of_sneakers",
            "photo_of_eyeglasses"
          ],
          "description": "One of the image class presets provided by the API."
        },
        "class_images": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "minItems": 1,
          "maxItems": 1000,
          "description": "List of accessible image URLs to be used as class images. Only required for Prior Preservation."
        },
        "class_prompt": {
          "type": "string",
          "description": "The prompt to specify images in the same class as provided instance images."
        },
        "with_prior_preservation": {
          "type": "boolean",
          "default": false,
          "description": "Flag to add prior preservation loss."
        },
        "prior_loss_weight": {
          "type": "number",
          "default": 1,
          "description": "The weight of prior preservation loss."
        },
        "seed": {
          "type": "number",
          "description": "A seed for reproducible training."
        },
        "resolution": {
          "type": "number",
          "minimum": 256,
          "maximum": 1024,
          "default": 1024,
          "description": "The resolution for input images, all the images in the train/validation dataset will be resized to this resolution"
        },
        "center_crop": {
          "type": "boolean",
          "default": false,
          "description": "Whether to center crop the input images to the resolution. If not set, the images will be randomly cropped. The images will be resized to the resolution first before cropping."
        },
        "train_text_encoder": {
          "type": "boolean",
          "default": false,
          "description": "Whether to train the text encoder along with the model."
        },
        "max_train_steps": {
          "type": "number",
          "minimum": 500,
          "maximum": 20000,
          "default": 500,
          "description": "Total number of training steps to perform."
        },
        "learning_rate": {
          "type": "number",
          "minimum": 1e-8,
          "maximum": 0.01,
          "default": 0.0005,
          "description": "Initial learning rate (after the potential warmup period) to use."
        },
        "scale_lr": {
          "type": "boolean",
          "default": false,
          "description": "Scale the learning rate by gradient accumulation steps and batch size."
        },
        "lr_scheduler": {
          "type": "string",
          "enum": ["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"],
          "default": "constant",
          "description": "The scheduler type to use."
        },
        "lr_warmup_steps": {
          "type": "number",
          "minimum": 0,
          "maximum": 20000,
          "default": 500,
          "description": "Number of steps for the warmup in the lr scheduler."
        },
        "lr_num_cycles": {
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "default": 1,
          "description": "Number of hard resets of the lr in cosine_with_restarts scheduler."
        },
        "lr_power": {
          "type": "number",
          "minimum": 0,
          "maximum": 5,
          "default": 1,
          "description": "Power factor for polynomial scheduler."
        },
        "use_8bit_adam": {
          "type": "boolean",
          "default": false,
          "description": "Whether or not to use 8-bit Adam from bitsandbytes."
        },
        "adam_beta1": {
          "type": "number",
          "default": 0.9,
          "description": "The beta1 parameter for the Adam optimizer."
        },
        "adam_beta2": {
          "type": "number",
          "default": 0.999,
          "description": "The beta2 parameter for the Adam optimizer."
        },
        "adam_weight_decay": {
          "type": "number",
          "default": 0.01,
          "description": "Weight decay to use for the model params."
        },
        "adam_epsilon": {
          "type": "number",
          "default": 1e-8,
          "description": "Epsilon value for the Adam optimizer."
        },
        "max_grad_norm": {
          "type": "number",
          "default": 1,
          "description": "Max gradient norm."
        },
        "text_encoder_use_attention_mask": {
          "type": "boolean",
          "default": false,
          "description": "Whether to use attention mask for text encoder."
        },
        "class_labels_conditioning": {
          "type": "string",
          "enum": ["timesteps"],
          "description": "The optional `class_label` conditioning to pass to the unet"
        },
        "rank": {
          "type": "number",
          "default": 4,
          "description": "The dimension of the LoRA update matrices."
        },
        "train_batch_size": {
          "type": "integer",
          "minimum": 1,
          "maximum": 1,
          "default": 1,
          "description": "Batch size for the training dataloader."
        },
        "repeats": {
          "type": "number",
          "default": 1
        },
        "random_flip": {
          "type": "boolean",
          "default": false,
          "description": "whether to randomly flip images horizontally"
        },
        "text_encoder_lr": {
          "type": "number",
          "minimum": 1e-8,
          "maximum": 0.01,
          "default": 0.000005,
          "description": "Text encoder learning rate to use."
        },
        "snr_gamma": {
          "type": "number",
          "description": "SNR weighting gamma to be used if rebalancing the loss. Recommended value is 5.0. More details here: https://arxiv.org/abs/2303.09556."
        },
        "optimizer": {
          "type": "string",
          "enum": ["AdamW", "prodigy"],
          "default": "AdamW",
          "description": "The optimizer to use."
        },
        "prodigy_beta3": {
          "type": "number",
          "description": "coefficients for computing the Prodidy stepsize using running averages. If null, uses the value of square root of beta2. Ignored if optimizer is adamW"
        },
        "prodigy_decouple": {
          "type": "boolean",
          "default": true,
          "description": "Use AdamW style decoupled weight decay"
        },
        "adam_weight_decay_text_encoder": {
          "type": "number",
          "default": 0.001,
          "description": "Weight decay to use for text_encoder"
        },
        "prodigy_use_bias_correction": {
          "type": "boolean",
          "default": true,
          "description": "Turn on Adam's bias correction. True by default. Ignored if optimizer is adamW"
        },
        "prodigy_safeguard_warmup": {
          "type": "boolean",
          "default": true,
          "description": "Remove lr from the denominator of D estimate to avoid issues during warm-up stage. True by default. Ignored if optimizer is adamW"
        }
      },
      "required": ["instance_prompt", "instance_images"],
      "additionalProperties": false
    },
    "type": {
      "type": "string",
      "enum": ["lora"]
    }
  },
  "required": ["model", "params", "type"],
  "additionalProperties": false
}
