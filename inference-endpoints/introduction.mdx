---
title: "Introduction"
description: "Introduction to SIE"
---

## Welcome

# Overview

Instantly deploy ML production inference to thousands of dedicated GPUs - at the lowest cost in the market.

- What is SIE?
  - SIE is a one-click API that allow you to scale AI/ML inferences to infinity without configuring infrastructure, all at the lowest cost in the market.
  - SIE API is the lowest priced API today, powered by Salad's unique distributed architecture.
- How does SIE work?
  - Salad Inference Endpoints (SIE) allows developers to deploy deep learning models for production-scale inference via simple API calls. Teams accustomed to hyperscale solutions will find the workflow similar to that of AWS Sagemaker Inference APIs.

## Inference Endpoints Marketplace

<img src="https://files.readme.io/9be5e8c-image.png" alt="Hero Dark" />

Navigate to the Inference Endpoints Marketplace by clicking the Inference Endpoints link in the left sidebar. You will see the models that are currently available.

## API Endpoints

<img src="https://files.readme.io/ed93535-image.png" alt="Hero Dark" />

### Authentication

To use the Inference Endpoint APIs, you will need your Salad API Key. You can find the API Key in the upper right hand Account drop down menu.

<img src="https://files.readme.io/3fdf865-image.png" alt="Hero Dark" />

<img src="https://files.readme.io/f4a2e32-image.png" alt="Hero Dark" />
