---
title: How to Generate Audio Chapters from transcriptions
---

_Last Updated: March 28, 2025_

By using our integrated custom LLM prompts, you can create a list of 'chapters' in your transcription. To use this, you
just need to add the `custom_prompt` input parameter to your transcription request.

## Custom input parameters

In this example, we'll use a Python script to transcribe an audio file and tell it to use the `custom_prompt` input
parameter to create a list of chapters, with titles, and a brief outline of what is contained. We'll use the following
input parameters:

```python
payload = {"input": {
        "custom_prompt": "Create a list of chapters from the transcription. Each chapter should have a title and a brief outline of what is contained in the chapter. The chapters should be in the format: Chapter 1: Title - Outline. The outline should be a brief summary of the chapter's content. Each chapter should be separated by a new line.",
        "url": audio_file_url,
        "language_code": "en",
        "return_as_file": False
    }}
```

## Python script

We'll use it in the following Python script:

```python
import requests
import time

audio_file_url = "url/to/audio/file.mp3"

salad_api_key = "YOUR_SALAD_API_KEY" # replace with your Salad API key
organization_name = "YOUR_ORGANIZATION_NAME" #Â replace with your organization name

payload = {"input": {
        "custom_prompt": "Create a list of chapters from the transcription. Each chapter should have a title and a brief outline of what is contained in the chapter. The chapters should be in the format: Chapter 1: Title - Outline. The outline should be a brief summary of the chapter's content. Each chapter should be separated by a new line.",
        "url": audio_file_url,
        "language_code": "en",
        "return_as_file": False
    }}
headers = {
    "Salad-Api-Key": salad_api_key,
    "Content-Type": "application/json"
}


url = f"https://api.salad.com/api/public/organizations/{organization_name}/inference-endpoints/transcribe/jobs"

response = requests.post(url, json=payload, headers=headers)

response = response.json()
job_id=response["id"]
print (f'Job ID: {job_id}')

while True:
  time.sleep(5)
  try:
      result = requests.get(f"{url}/{job_id}", headers=headers)
      result = result.json()
      if result["status"] == "created" or result["status"] == "pending" or result["status"] == "started" or result["status"] == "running":
          print(f'Current job status is {result["status"]}')
      elif result["status"] == "failed":
          print(f'Job failed')
          break
      elif result["output"]:
          print(result["output"]["llm_result"])
          break
      else:
          print(f'Current job status is {result["status"]}')
  except Exception as e:
        print(f'Error retrieving transcription result: {e}')
        break
```

- Make sure to replace `url/to/audio/file.mp3` with the URL of your audio file.
- Replace `YOUR_SALAD_API_KEY` with
  [your Salad API key](products/sce/getting-started/quickstart-api#step-1-obtain-your-api-key).
- Replace `YOUR_ORGANIZATION_NAME` with your organization name.

In this script, we're telling Salad to use the `custom_prompt` LLM feature to create the list of chapters. The output
will be returned in the `llm_result` field of the response. We're then printing the result of this field to the console.
It'll look something like this once it finishes:

### Output

```bash
Job ID: abcfaf6c-7323-41e8-b81b-ecc7709066ed
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Current job status is running
Transcription Result: Chapter 1: Introduction - Overview of NVIDIA's 50 series RTX GPUs and the controversy surrounding them.

Chapter 2: The Keynote - Description of NVIDIA's keynote presentation where they revealed their 50 series RTX GPUs and made claims about the performance of the RTX 5070.

Chapter 3: Red Flags - Discussion of how Jensen Wong's statement that achieving RTX 4090 performance without AI would be impossible raised suspicions about the use of fake frames in the 50 series cards.

Chapter 4: The Perception Shift - Explanation of how public perception shifted from excitement to skepticism as people began to understand how the 50 series cards were able to achieve such great performance through DLSS software and frame gen.
```

At this time, timestamps are **not** supported for creating chapters. The custom `llm_prompt` only views the "text"
field response from the transcription completion, and so currently is unable to see the timestamps of the quotes.
